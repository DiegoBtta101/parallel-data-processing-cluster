# Parallel Data Processing with Docker Swarm and NFS

This project demonstrates a distributed system for parallel processing of a large dataframe using Docker Swarm and a shared NFS volume. It was deployed on a physical cluster built from repurposed computer boards, showcasing real-world infrastructure design, automation, and orchestration.

---

## üîç Overview

The objective is to process a large CSV file in parallel by splitting the workload across several worker nodes coordinated by a master node. The communication between nodes and data sharing is managed through Docker Swarm and a shared NFS-mounted volume.

This system reflects a real-world DevOps workflow involving infrastructure setup, container orchestration, network configuration, and distributed computation using Python.

---

## üß± Architecture

```
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ      Master Node     ‚îÇ
               ‚îÇ                      ‚îÇ
               ‚îÇ  split_dataframe.py  ‚îÇ
               ‚îÇ     deploys jobs     ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
               ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
               ‚îÇ  Shared NFS Volume   ‚îÇ
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚ñº                  ‚ñº                  ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Worker #1  ‚îÇ     ‚îÇ Worker #2  ‚îÇ ... ‚îÇ Worker #N  ‚îÇ
‚îÇ process.py ‚îÇ     ‚îÇ process.py ‚îÇ     ‚îÇ process.py ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Tech Stack

- Docker & Docker Swarm  
- Python (Pandas, time)  
- NFS (Network File System)  
- Linux (Ubuntu/Debian)  
- Bash scripting   
- SSH   
- Parallel execution and result aggregation  

---

## üöÄ Project Workflow

1. **Setup NFS:**
   - A master node exports an NFS folder.
   - All nodes mount this shared volume to a known path.

2. **Initialize Docker Swarm:**
   - Master node runs `docker swarm init`.
   - Worker nodes join the cluster using the token.

3. **Deploy Containers:**
   - The master splits the dataframe and writes chunked files to NFS.
   - A service is deployed via `docker stack deploy`, spawning processing containers.
   - Each container processes one chunk and writes the result to NFS.

4. **Collect Results:**
   - After all tasks complete, a final container collects partial results and merges them.

---

## üìÇ Repository Structure

```
.
‚îú‚îÄ‚îÄ docker-compose.yml           # Swarm stack definition
‚îú‚îÄ‚îÄ docker/                      # Dockerfiles for each processing role
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.split
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.processing
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile.result
‚îú‚îÄ‚îÄ scripts/                     # Python scripts executed in containers
‚îÇ   ‚îú‚îÄ‚îÄ split_dataframe.py
‚îÇ   ‚îú‚îÄ‚îÄ split_processing.py
‚îÇ   ‚îî‚îÄ‚îÄ collect_results.py
‚îú‚îÄ‚îÄ infra/                       # Infrastructure setup
‚îÇ   ‚îú‚îÄ‚îÄ NFS_setup.md
‚îÇ   ‚îú‚îÄ‚îÄ Swarm_setup.md
‚îÇ   ‚îî‚îÄ‚îÄ commands_cheatsheet.md
‚îî‚îÄ‚îÄ README.md
```

---

## üì∏ Example Output

After completion, the result folder contains processed CSV chunks and a final merged output file.

```
[‚úì] Split file into 6 chunks  
[‚úì] Deployed 6 worker containers  
[‚úì] Each processed 1 chunk  
[‚úì] Collected 6 result files  
[‚úì] Final file merged successfully  
```

---

## üîê Notes

> This project is intended for educational and demonstrative purposes. It assumes basic knowledge of Docker, Linux networking, and Python scripting. It was developed and tested on a physical multi-node environment, but can be adapted to virtualized or cloud-based infrastructure.

---

## ‚úçÔ∏è Author

**Diego Bautista**  
Electronic Engineer & DevOps Enthusiast  
[Portfolio](https://diegobtta101.github.io) ‚Ä¢ [GitHub](https://github.com/DiegoBtta101)

---

## üìú License

MIT License. See `LICENSE` for details.
